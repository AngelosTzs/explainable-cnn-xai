# Explainable CNN with Saliency Maps & Grad-CAM (CIFAR-10)

This project visualizes how a Convolutional Neural Network (CNN) interprets image classification using two popular explainable AI techniques:

- **Saliency Maps**: Highlight the most influential pixels for the modelâ€™s decision.
- **Grad-CAM**: Visualize class-specific regions learned by convolutional layers.

ğŸ§  **Model**: Custom CNN trained on CIFAR-10  
ğŸ“š **Dataset**: CIFAR-10 (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck)  
ğŸ› ï¸ **Tech stack**: Python, TensorFlow, NumPy, OpenCV, Matplotlib, Tkinter

---

## ğŸš€ Features

- Train a simple CNN on CIFAR-10 with accuracy/loss visualization.
- Apply Saliency Map and Grad-CAM for explainability.
- GUI (Tkinter) to select and analyze test images.
- Greek-language description popup per prediction.
- Navigation buttons and visualization controls.

---

## ğŸ–¥ï¸ Example Output

*(Optional: Add image files in `/results/` and link them here)*

|               Original                   |                Saliency Map              |               Grad-CAM                 |
|------------------------------------------|------------------------------------------|----------------------------------------|
| ![original](results/sample_original.png) | ![saliency](results/sample_saliency.png) | ![gradcam](results/sample_gradcam.png) |

---

## ğŸ“¦ Installation

Create a virtual environment and install dependencies:

```bash
pip install -r requirements.txt
```

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).

